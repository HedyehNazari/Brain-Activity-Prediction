{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HedyehNazari/Brain-Activity-Prediction/blob/main/Convnet_For_Brain_Activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVqSM9IAm-r_"
      },
      "source": [
        "#setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzhRR8bDd3oe"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ1nv_qxgghQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc32f0c-6961-44a8-ab38-0e83e6c91035"
      },
      "source": [
        "## Colab setting\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/\n",
        "#%mkdir -p Neuromatch\n",
        "%cd Neuromatch/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/MyDrive/'\n",
            "/content/gdrive/MyDrive/Neuromatch\n",
            "[Errno 2] No such file or directory: 'Neuromatch/'\n",
            "/content/gdrive/MyDrive/Neuromatch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akTW1-VGGUgz"
      },
      "source": [
        "## Download the dataset\n",
        "fname = \"kay_labels.npy\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/r638s/download\n",
        "fname = \"kay_labels_val.npy\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/yqb3e/download\n",
        "fname = \"kay_images.npz\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/ymnjv/download\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tL4ohJ1GqYb"
      },
      "source": [
        "## Load the data\n",
        "with np.load(fname) as dobj:\n",
        "    dat = dict(**dobj)\n",
        "labels = np.load('kay_labels.npy')\n",
        "val_labels = np.load('kay_labels_val.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZxz11EQcFk1"
      },
      "source": [
        "##configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3NxMu8uuAAr"
      },
      "source": [
        "config={\n",
        "    'DEVICE' : torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'TRAIN_SIZE' : 1400,\n",
        "    'epoch' : 100,\n",
        "    'BATCH_SIZE': 16,\n",
        "    'CHECKPOINT': 'checkpoint',\n",
        "    'LOAD_FROM_FILE': True,\n",
        "\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9zhwgU2-1il"
      },
      "source": [
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9yCDYs9rE5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef875b01-4d64-4d93-ea8b-4ff9f1183448"
      },
      "source": [
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random seed 2021 has been set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNH3ve3onZKj"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwKa2JxInayk"
      },
      "source": [
        "def count_errors(y_prediction, y_true, std=1):\n",
        "  return torch.sum(torch.abs(y_prediction - y_true) > std).item()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTv5aZDZneWu"
      },
      "source": [
        "def correlation(x, y):\n",
        "  vx = x - torch.mean(x)\n",
        "  vy = y - torch.mean(y)\n",
        "  return torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfAUQUyNnhQe"
      },
      "source": [
        "## Function to save a model and its optimizer to drive\n",
        "def save(name: str, model: nn.Module, optimizer: optim.Optimizer, epoch: int):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq5eYuhbnoJu"
      },
      "source": [
        "## Function to load a model and its optimizer from drive\n",
        "def load(name: str, model: nn.Module, optimizer: optim.Optimizer):\n",
        "    checkpoint = torch.load(name)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tbMeGDfbFDS"
      },
      "source": [
        "def l1_reg(model):\n",
        "  l1 = 0.0\n",
        "  for param in model.parameters():\n",
        "    l1 += torch.sum(torch.abs(param))\n",
        "  return l1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVKhpGxCaxIV"
      },
      "source": [
        "def l2_reg(model):\n",
        "  l2 = 0.0\n",
        "  for param in model.parameters():\n",
        "    l2 += torch.sum(torch.abs(param)**2)\n",
        "  return l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n90gEf2qa-fi"
      },
      "source": [
        "def roi_voxels(dat):\n",
        "  v1,v2,v3,v3A,v3B,LatOcc,v4 = [],[],[],[],[],[],[]\n",
        "  for voxel in range(8428):\n",
        "    if dat['roi'][voxel]==1:\n",
        "      v1.append(voxel) \n",
        "    elif dat['roi'][voxel]==2:\n",
        "      v2.append(voxel)\n",
        "    elif dat['roi'][voxel]==3:\n",
        "      v3.append(voxel)\n",
        "    elif dat['roi'][voxel]==4:\n",
        "      v3A.append(voxel)\n",
        "    elif dat['roi'][voxel]==5:\n",
        "      v3B.append(voxel)\n",
        "    elif dat['roi'][voxel]==6:\n",
        "      v4.append(voxel)\n",
        "    elif dat['roi'][voxel]==7:\n",
        "      LatOcc.append(voxel)\n",
        "  voc = np.array([v1,v2,v3,v3A,v3B,LatOcc,v4])\n",
        "  return voc\n",
        "\n",
        "def mean_roi(dat,voc):\n",
        "  v1_mean = np.mean(dat['responses'][:,voc[0]],axis=1)\n",
        "  v2_mean = np.mean(dat['responses'][:,voc[1]],axis=1)\n",
        "  v3_mean = np.mean(dat['responses'][:,voc[2]],axis=1)\n",
        "  v3A_mean = np.mean(dat['responses'][:,voc[3]],axis=1)\n",
        "  v3B_mean = np.mean(dat['responses'][:,voc[4]],axis=1)\n",
        "  v4_mean = np.mean(dat['responses'][:,voc[5]],axis=1)\n",
        "  LatOcc_mean = np.mean(dat['responses'][:,voc[6]],axis=1)\n",
        "  response = np.transpose(np.array([v1_mean,v2_mean,v3_mean,v3A_mean,v3B_mean,v4_mean,LatOcc_mean]))\n",
        "  return response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxS35wmZKRUu"
      },
      "source": [
        "##Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRbIWBiNeXvS"
      },
      "source": [
        "class ImageSignalDataset(Dataset):\n",
        "  def __init__(self, images, signals, image_transform=None, signal_transform=None):\n",
        "    '''\n",
        "      images is a n * 128 * 128 numpy array\n",
        "      signals is a n * 8428 numpy array\n",
        "    '''\n",
        "    self.images = images\n",
        "    self.signals = signals\n",
        "    self.image_transform = image_transform\n",
        "    self.signal_transform = signal_transform\n",
        "    assert images.shape[0] == signals.shape[0]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.images.shape[0]\n",
        "\n",
        "  ## TODO: signal_transform not working\n",
        "  def __getitem__(self, index):\n",
        "    x = self.image_transform(self.images[index, :, :]) if self.image_transform else self.images[index, :, :]\n",
        "    y = torch.tensor(self.signals[index, :])\n",
        "    # y = self.signal_transform(self.signals[index, :]) if self.signal_transform else self.signals[index, :]\n",
        "    return x, y\n",
        "# print(dat[\"stimuli\"].shape)\n",
        "# print(dat[\"responses\"].shape)\n",
        "#d = ImageSignalDataset(dat[\"stimuli\"],dat[\"responses\"],image_transform=ToTensor())\n",
        "# x,y = d[50]\n",
        "# print(x.shape)\n",
        "# print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYznSOOt0K6m",
        "outputId": "1fad0aeb-992e-423b-a016-29dc30db6cd4"
      },
      "source": [
        "print(dat.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['stimuli', 'stimuli_test', 'responses', 'responses_test', 'roi', 'roi_names'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izfWIkMM1Dpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5109cd30-6808-49ee-c006-2de770c65d0e"
      },
      "source": [
        "trainset = ImageSignalDataset(dat['stimuli'][:config['TRAIN_SIZE'], :, :], dat['responses'][:config['TRAIN_SIZE'], :], image_transform = ToTensor(), signal_transform = ToTensor())\n",
        "validationset = ImageSignalDataset(dat['stimuli'][config['TRAIN_SIZE']:, :, :], dat['responses'][config['TRAIN_SIZE']:, :], image_transform = ToTensor(), signal_transform = ToTensor())\n",
        "testset = ImageSignalDataset(dat['stimuli_test'], dat['responses_test'], image_transform = ToTensor(), signal_transform = ToTensor())\n",
        "\n",
        "train_loader = DataLoader(trainset, config['BATCH_SIZE'], shuffle=True)\n",
        "validation_loader = DataLoader(validationset, config['BATCH_SIZE'], shuffle=False)\n",
        "test_loader = DataLoader(testset, config['BATCH_SIZE'], shuffle=False)\n",
        "\n",
        "\n",
        "print(f'trainset contains: {len(trainset)} pairs of image/signals')\n",
        "print(f'valset   contains: {len(validationset)}  pairs of image/signals')\n",
        "print(f'testset  contains: {len(testset)}  pairs of image/signals')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainset contains: 1400 pairs of image/signals\n",
            "valset   contains: 350  pairs of image/signals\n",
            "testset  contains: 120  pairs of image/signals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyrHjYoeoT8V"
      },
      "source": [
        "##CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ0hLC2ejhhI"
      },
      "source": [
        "class Convnet(nn.Module):\n",
        "   def __init__(self):\n",
        "     super().__init__()\n",
        "     self.conv1 = nn.Conv2d(in_channels=1,out_channels=4, kernel_size=8, stride=2, padding = 0) #4*61*61\n",
        "     self.conv2 = nn.Conv2d(in_channels=4,out_channels=8, kernel_size=8, stride=2, padding = 0) #8*27*27\n",
        "     self.conv3 = nn.Conv2d(in_channels=8,out_channels=16, kernel_size=8, stride=2, padding = 0) #16*10*10\n",
        "     self.bn1  = nn.BatchNorm2d(4)\n",
        "     self.bn2  = nn.BatchNorm2d(8)\n",
        "     self.bn3  = nn.BatchNorm2d(16)\n",
        "     self.drp  = nn.Dropout2d(0.5)    \n",
        "     self.fc1 = nn.Linear(16*10*10,4000)\n",
        "     #self.bn1d  = nn.BatchNorm1d(4000)\n",
        "     self.fc2 = nn.Linear(4000,8428)\n",
        "   def forward(self,x):\n",
        "      x =  self.conv1(x) \n",
        "      x = nn.functional.relu(x)\n",
        "      x =  self.bn1(x)\n",
        "      x = self.drp(x)\n",
        "      #print(x.shape)\n",
        "      x =  self.conv2(x)\n",
        "      x = nn.functional.relu(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.drp(x)\n",
        "      #print(x.shape)\n",
        "      x =  self.conv3(x) \n",
        "      x = nn.functional.relu(x)\n",
        "      x = self.bn3(x)\n",
        "      #print(x.shape)\n",
        "      x = torch.flatten(x,1)\n",
        "      x = self.fc1(x)\n",
        "      #print(x.shape)\n",
        "      #x =  self.bn1d(x)\n",
        "      x = nn.functional.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      return x\n",
        "# model = Convnet().to(DEVICE)\n",
        "\n",
        "# for batch in train_loader:\n",
        "#   x,y = batch\n",
        "#   x = x.to(DEVICE)\n",
        "#   y = y.to(DEVICE)\n",
        "#   z = c(x)\n",
        "#   print(\"x shape\",x.shape)\n",
        "#   print(\"z shape\",z.shape)\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr0oWLabz4sL"
      },
      "source": [
        "## Trainingloop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQGvWBHmosGV"
      },
      "source": [
        "model = Convnet().to(config['DEVICE'])\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0001) \n",
        "loss_fn = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSWkOJ5LTJ_9",
        "outputId": "839875c3-7b6f-4960-e4a8-24add963cc67"
      },
      "source": [
        "# Load model and optimizer from drive\n",
        "if config['LOAD_FROM_FILE']:\n",
        "  load('checkpoint30.pt', model, optimizer)\n",
        "  print('Model loaded!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj0_-34apqH1"
      },
      "source": [
        "\n",
        "train_losses, val_losses, val_mistake, train_mistake,val_mistake_correlation,train_mistake_correlation  = [],[],[],[],[],[]\n",
        "for epoch in range(config['epoch']):\n",
        "  train_loss_sum = 0\n",
        "  val_loss_sum = 0\n",
        "  val_errors = 0\n",
        "  total_e1 = 0.0\n",
        "  total_e2 = 0.0\n",
        "\n",
        "  model.train()\n",
        "  for batch in train_loader:\n",
        "    x,y = batch\n",
        "    x = x.to(config['DEVICE'])\n",
        "    y = y.float()\n",
        "    y = y.to(config['DEVICE'])\n",
        "    optimizer.zero_grad()\n",
        "    z = model(x)\n",
        "    \n",
        "    outputloss = loss_fn(z, y)\n",
        "    #outputloss += 0.0005 * l1_reg(model)\n",
        "    outputloss += 0.0005* l2_reg(model)\n",
        "    outputloss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss_sum += outputloss.detach().item()\n",
        "    total_e1 += count_errors(z.detach(), y.detach())\n",
        "    total_e2 += correlation(z.detach(), y.detach())\n",
        "    \n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    totalerror1 = 0\n",
        "    totalerror2 = 0\n",
        "    for batch in validation_loader:\n",
        "      x,y = batch\n",
        "      x = x.to(config['DEVICE'])\n",
        "      y = y.float()\n",
        "      y = y.to(config['DEVICE'])\n",
        "      z = model(x)\n",
        "      outputloss = loss_fn(z, y)\n",
        "      \n",
        "      val_loss_sum += outputloss.detach().item()\n",
        "      totalerror1 += count_errors(z.detach(), y.detach())\n",
        "      totalerror2 += correlation(z.detach(), y.detach())\n",
        "\n",
        "\n",
        "  train_losses.append(train_loss_sum )\n",
        "  val_losses.append(val_loss_sum )\n",
        "  print(f'Epoch {epoch}: Loss = {train_loss_sum}')\n",
        "\n",
        "  #counterror calculation\n",
        "  val_mistake.append(totalerror1 / len(validationset))\n",
        "  train_mistake.append(total_e1 / len(trainset))\n",
        "\n",
        "  #correlation calculation\n",
        "  val_mistake_correlation.append(totalerror2 / len(validationset))\n",
        "  train_mistake_correlation.append(total_e2 / len(trainset))\n",
        " \n",
        "\n",
        "  #every 10 epochs, save the model\n",
        "  if epoch % 10 == 0:\n",
        "    save(config['CHECKPOINT'] + f'{epoch}.pt', model, optimizer, epoch)\n",
        "    print('Model saved!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "UHb4ani7vdzW",
        "outputId": "6d82c24a-1ec1-4b2c-afa4-91c30b43f924"
      },
      "source": [
        "print(\"train_losses:\",train_losses)\n",
        "print(\"val_losses:  \",val_losses)\n",
        "print(min(val_losses), np.argmin(val_losses))\n",
        "print(\"val_mistake:     \",val_mistake)\n",
        "print(\"train_mistake:   \",train_mistake)\n",
        "print(\"train_mistake_correlation:     \",train_mistake_correlation)\n",
        "print(\"val_mistake_correlation:   \",val_mistake_correlation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-d39d45836aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_losses:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val_losses:  \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val_mistake:     \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_mistake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_mistake:   \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_mistake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "TBC81EjAA5fv",
        "outputId": "65ade3bf-754e-4280-d53b-b1e0d604b607"
      },
      "source": [
        "\n",
        "plt.plot(np.arange(len(train_losses)), train_losses, 'r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train Loss')\n",
        "plt.savefig(\"Train Loss\", dpi=300, format='JPEG')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(val_losses)), val_losses, 'b')\n",
        "plt.xlabel('Epoch')\n",
        "plt.savefig(\"Val Loss\", dpi=300, format='JPEG')\n",
        "plt.ylabel('Val Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(train_mistake)), train_mistake, 'r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train Mistake')\n",
        "plt.savefig(\"Train Mistake\", dpi=300, format='JPEG')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(val_mistake)), val_mistake, 'b')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Val Mistake')\n",
        "plt.savefig(\"Val Mistake\", dpi=300, format='JPEG')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(train_mistake_correlation)), train_mistake_correlation, 'r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train Mistake Correlation')\n",
        "plt.savefig(\"Train Mistake Correlation\", dpi=300, format='JPEG')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(len(val_mistake_correlation)), val_mistake_correlation, 'b')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Val Mistake Correlation')\n",
        "plt.savefig(\"Val Mistake Correlation\", dpi=300, format='JPEG')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-f0f689b72d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'JPEG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3ZikycgDXk0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "47943628-5f0b-4646-bbde-8f9ebd82918f"
      },
      "source": [
        "plt.plot(np.arange(len(train_losses)), np.array(train_losses)/len(trainset), 'r')\n",
        "plt.plot(np.arange(len(val_losses)), np.array(val_losses)/len(validationset), 'b')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShdLS7Hmu7u0"
      },
      "source": [
        "# evaluation 1\n",
        "# batch_normalization 1\n",
        "# dropout  befor or after relu 0\n",
        "# ploting\n",
        "#hyperparameters\n",
        "#correlation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h731NJKSTmut",
        "outputId": "b4b51005-abf5-48e1-e6c7-3fa5d97fb793"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  total, V1_total_val_mistakes, V2_total_val_mistakes, V3_total_val_mistakes, V4_total_val_mistakes, V7_total_val_mistakes = 0, 0, 0, 0, 0, 0\n",
        "  for images, labels in validation_loader:\n",
        "    images = images.to(config['DEVICE'])\n",
        "    labels = labels.to(config['DEVICE']).float()\n",
        "    # images = ae_model.enc5(ae_model.enc4(ae_model.enc3(ae_model.enc2(ae_model.enc1(images)))))\n",
        "    # features = torch.flatten(images, 1).detach()\n",
        "\n",
        "    predictions = model(images)\n",
        "\n",
        "    v1_predictions = predictions [:, dat['roi'] == 1]\n",
        "    v1_labels = labels [:, dat['roi'] == 1]\n",
        "\n",
        "    v2_predictions = predictions [:, dat['roi'] == 2]\n",
        "    v2_labels = labels [:, dat['roi'] == 2]\n",
        "\n",
        "    v3_predictions = predictions [:, dat['roi'] == 3]\n",
        "    v3_labels = labels [:, dat['roi'] == 3]\n",
        "\n",
        "    v4_predictions = predictions [:, dat['roi'] == 6]\n",
        "    v4_labels = labels [:, dat['roi'] == 6]\n",
        "\n",
        "    v7_predictions = predictions [:, dat['roi'] == 7]\n",
        "    v7_labels = labels [:, dat['roi'] == 7]\n",
        "\n",
        "    # print(v1_labels.shape, v2_labels.shape, v3_labels.shape, v4_labels.shape)\n",
        "    # break\n",
        "    \n",
        "    V1_total_val_mistakes += count_errors(v1_labels, v1_predictions)\n",
        "    V2_total_val_mistakes += count_errors(v2_labels, v2_predictions)\n",
        "    V3_total_val_mistakes += count_errors(v3_labels, v3_predictions)\n",
        "    V4_total_val_mistakes += count_errors(v4_labels, v4_predictions)\n",
        "    V7_total_val_mistakes += count_errors(v7_labels, v7_predictions)\n",
        "    total += count_errors(labels, predictions)\n",
        "\n",
        "print(f'V1 prediction accuracy is {1 - (V1_total_val_mistakes/ len(validationset) / 1294)}')\n",
        "print(f'V2 prediction accuracy is {1 - (V2_total_val_mistakes/ len(validationset) / 2083)}')\n",
        "print(f'V3 prediction accuracy is {1 - (V3_total_val_mistakes/ len(validationset) / 1790)}')\n",
        "print(f'V4 prediction accuracy is {1 - (V4_total_val_mistakes/ len(validationset) / 1535)}')\n",
        "print(f'V7 prediction accuracy is {1 - (V7_total_val_mistakes/ len(validationset) / 928)}')\n",
        "print(f'Total prediction accuracy is {1 - (total/ len(validationset) / 8428)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "V1 prediction accuracy is 0.6901192316184588\n",
            "V2 prediction accuracy is 0.6911514985254783\n",
            "V3 prediction accuracy is 0.6894924181963288\n",
            "V4 prediction accuracy is 0.6876240111679851\n",
            "V7 prediction accuracy is 0.6860283251231527\n",
            "Total prediction accuracy is 0.689140958709065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kTnmSe1nCAa",
        "outputId": "ab1fe9ff-9a0f-4323-d09a-bc20b86f95ae"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  total, V1_total_val_mistakes, V2_total_val_mistakes, V3_total_val_mistakes, V4_total_val_mistakes, V7_total_val_mistakes = 0, 0, 0, 0, 0, 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(config['DEVICE'])\n",
        "    labels = labels.to(config['DEVICE']).float()\n",
        "    # images = ae_model.enc5(ae_model.enc4(ae_model.enc3(ae_model.enc2(ae_model.enc1(images)))))\n",
        "    # features = torch.flatten(images, 1).detach()\n",
        "\n",
        "    predictions = model(images)\n",
        "\n",
        "    v1_predictions = predictions [:, dat['roi'] == 1]\n",
        "    v1_labels = labels [:, dat['roi'] == 1]\n",
        "\n",
        "    v2_predictions = predictions [:, dat['roi'] == 2]\n",
        "    v2_labels = labels [:, dat['roi'] == 2]\n",
        "\n",
        "    v3_predictions = predictions [:, dat['roi'] == 3]\n",
        "    v3_labels = labels [:, dat['roi'] == 3]\n",
        "\n",
        "    v4_predictions = predictions [:, dat['roi'] == 6]\n",
        "    v4_labels = labels [:, dat['roi'] == 6]\n",
        "\n",
        "    v7_predictions = predictions [:, dat['roi'] == 7]\n",
        "    v7_labels = labels [:, dat['roi'] == 7]\n",
        "\n",
        "    # print(v1_labels.shape, v2_labels.shape, v3_labels.shape, v4_labels.shape)\n",
        "    # break\n",
        "    \n",
        "    V1_total_val_mistakes += count_errors(v1_labels, v1_predictions)\n",
        "    V2_total_val_mistakes += count_errors(v2_labels, v2_predictions)\n",
        "    V3_total_val_mistakes += count_errors(v3_labels, v3_predictions)\n",
        "    V4_total_val_mistakes += count_errors(v4_labels, v4_predictions)\n",
        "    V7_total_val_mistakes += count_errors(v7_labels, v7_predictions)\n",
        "    total += count_errors(labels, predictions)\n",
        "\n",
        "print(f'V1 prediction accuracy is {1 - (V1_total_val_mistakes/ len(test_loader) / 1294)}')\n",
        "print(f'V2 prediction accuracy is {1 - (V2_total_val_mistakes/ len(test_loader) / 2083)}')\n",
        "print(f'V3 prediction accuracy is {1 - (V3_total_val_mistakes/ len(test_loader) / 1790)}')\n",
        "print(f'V4 prediction accuracy is {1 - (V4_total_val_mistakes/ len(test_loader) / 1535)}')\n",
        "print(f'V7 prediction accuracy is {1 - (V7_total_val_mistakes/ len(test_loader) / 928)}')\n",
        "print(f'Total prediction accuracy is {1 - (total/ len(test_loader) / 8428)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "V1 prediction accuracy is 0.1655718701700154\n",
            "V2 prediction accuracy is 0.1899303888622179\n",
            "V3 prediction accuracy is 0.35342178770949717\n",
            "V4 prediction accuracy is 0.3690553745928339\n",
            "V7 prediction accuracy is 0.32610452586206895\n",
            "Total prediction accuracy is 0.28595158993830094\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}